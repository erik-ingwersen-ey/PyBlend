{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67031bd09bb0cb01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T04:20:26.689057Z",
     "start_time": "2024-08-30T04:20:26.684279Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlwings as xw\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b6cac2-2ad8-4a32-b56b-1ef1045ef15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlwings as xw\n",
    "import json\n",
    "\n",
    "wb = xw.Book(\"/Users/erikingwersen/Desktop/fileshare/out/excel/out_interactive.xlsm\")\n",
    "sheet = wb.sheets['Inputs']\n",
    "\n",
    "stockpiles = sheet['D2'].options(pd.DataFrame, expand='table').value.reset_index()\n",
    "rename_dict = {\"ID\": \"id\", \"Área\": \"yard\", \"Quantidade (ton)\": \"weightIni\"\n",
    "}\n",
    "stockpiles = stockpiles.rename(columns=rename_dict).astype({col: int for col in rename_dict.values()})\n",
    "\n",
    "yards = sheet['L2'].options(pd.DataFrame, expand='table').value.reset_index()\n",
    "\n",
    "engine_cols = [col for col in yards.columns if any(ch.isnumeric() for ch in col)]\n",
    "rename_dict = {col: \"\".join(ch for ch in col if ch.isnumeric()) for col in engine_cols}\n",
    "engine_ids = list(rename_dict.values())\n",
    "\n",
    "yards = yards.rename(columns=rename_dict).astype({\"yard\": int})\n",
    "yards[\"rails\"] = yards[engine_ids].apply(lambda row: [idx for idx, value in enumerate(row, 1) if pd.notna(value)], axis=1)\n",
    "yards = yards.drop(columns=engine_ids)\n",
    "\n",
    "stockpiles = stockpiles.merge(yards, on=\"yard\", how=\"left\")\n",
    "\n",
    "engines = (\n",
    "    sheet['P2'].options(pd.DataFrame, expand='table').value.reset_index()\n",
    "    .rename(columns={\"Veículo\": \"id\", \"Taxa (ton/min)\": \"speedReclaim\"})\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "\n",
    "rename_dict = {\"De\": \"from\", \"Para\": \"to\"}\n",
    "travel_speed = sheet['S2'].options(pd.DataFrame, expand='table').value.reset_index().rename(columns=rename_dict)\n",
    "\n",
    "stockpiles_from_to_cols = list(rename_dict.values())\n",
    "speed_cols = travel_speed.columns.difference(stockpiles_from_to_cols)\n",
    "travel_speed[\"travel_time\"] = travel_speed[speed_cols[0]]\n",
    "\n",
    "for col in speed_cols[1:]:\n",
    "    travel_speed[\"travel_time\"] = travel_speed[\"travel_time\"].fillna(travel_speed[col])\n",
    "\n",
    "travel_times = travel_speed.drop(columns=speed_cols).pivot_table(index=[\"from\"], columns=[\"to\"], values=[\"travel_time\"]).values.tolist()\n",
    "\n",
    "output_info = sheet[\"A2\"].options(pd.DataFrame, expand='table').value.reset_index()\n",
    "\n",
    "outputs = [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"destination\": 1,\n",
    "      \"weight\": int(output_info.iloc[0, 1]),\n",
    "      \"quality\": [\n",
    "        {\n",
    "          \"parameter\": \"Fe\",\n",
    "          \"minimum\": 60,\n",
    "          \"maximum\": 100,\n",
    "          \"goal\": 65,\n",
    "          \"importance\": 10\n",
    "        },\n",
    "        {\n",
    "          \"parameter\": \"SiO2\",\n",
    "          \"minimum\": 2.8,\n",
    "          \"maximum\": 5.8,\n",
    "          \"goal\": 5.8,\n",
    "          \"importance\": 1000\n",
    "        },\n",
    "        {\n",
    "          \"parameter\": \"Al2O3\",\n",
    "          \"minimum\": 2.5,\n",
    "          \"maximum\": 4.9,\n",
    "          \"goal\": 4.9,\n",
    "          \"importance\": 100\n",
    "        },\n",
    "        {\n",
    "          \"parameter\": \"P\",\n",
    "          \"minimum\": 0.05,\n",
    "          \"maximum\": 0.07,\n",
    "          \"goal\": 0.07,\n",
    "          \"importance\": 100\n",
    "        }\n",
    "      ],\n",
    "      \"time\": 600\n",
    "    }\n",
    "]\n",
    "inputs = [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"weight\": 0.0,\n",
    "      \"quality\": [\n",
    "        {\n",
    "          \"parameter\": \"Fe\",\n",
    "          \"value\": 60\n",
    "        },\n",
    "        {\n",
    "          \"parameter\": \"SiO2\",\n",
    "          \"value\": 1.5\n",
    "        },\n",
    "        {\n",
    "          \"parameter\": \"Al2O3\",\n",
    "          \"value\": 0.8\n",
    "        },\n",
    "        {\n",
    "          \"parameter\": \"P\",\n",
    "          \"value\": 1.0\n",
    "        }\n",
    "      ],\n",
    "      \"time\": 8.0\n",
    "    }\n",
    "]\n",
    "\n",
    "instance_data = {\n",
    "    \"info\": [\"Instance_Interactive\", 1000, 1],\n",
    "    \"stockpiles\": [],\n",
    "    \"engines\": [],\n",
    "    \"inputs\": inputs,\n",
    "    \"outputs\": outputs,\n",
    "    \"distancesTravel\": travel_times,\n",
    "    \"timeTravel\": travel_times\n",
    "}\n",
    "for _, row in stockpiles.iterrows():\n",
    "    sp = {\n",
    "        \"id\": int(row[\"id\"]),\n",
    "        \"position\": int(row[\"id\"]) - 1,\n",
    "        \"yard\": int(row[\"yard\"]),\n",
    "        \"rails\": [int(r) for r in row[\"rails\"]],\n",
    "        \"capacity\": int(row[\"weightIni\"]),\n",
    "        \"weightIni\": int(row[\"weightIni\"]),\n",
    "        \"qualityIni\": [\n",
    "            {\"parameter\": \"Fe\", \"value\": float(row[\"Fe\"])},\n",
    "            {\"parameter\": \"SiO2\", \"value\": float(row[\"SiO2\"])},\n",
    "            {\"parameter\": \"Al2O3\", \"value\": float(row[\"Al2O3\"])},\n",
    "            {\"parameter\": \"P\", \"value\": float(row[\"P\"])}\n",
    "        ]\n",
    "    }\n",
    "    instance_data[\"stockpiles\"].append(sp)\n",
    "\n",
    "all_yards = [int(y) for y in stockpiles[\"yard\"].drop_duplicates().to_list()]\n",
    "for _, row in engines.iterrows():\n",
    "    eng = {\n",
    "      \"id\": int(row[\"id\"]),\n",
    "      \"speedStack\": 0.0,\n",
    "      \"speedReclaim\": int(row[\"speedReclaim\"]),\n",
    "      \"posIni\": int(row[\"id\"]),\n",
    "      \"rail\": int(row[\"id\"]),\n",
    "      \"yards\": all_yards\n",
    "    }\n",
    "    instance_data[\"engines\"].append(eng)\n",
    "\n",
    "# Write the data to the JSON file\n",
    "with open('../tests/instance_11.json', 'w') as json_file:\n",
    "    json.dump(instance_data, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9aaab0c8fb85b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T04:19:56.995361Z",
     "start_time": "2024-08-30T04:19:56.200903Z"
    }
   },
   "outputs": [],
   "source": [
    "wb = xw.Book(\"/Users/erikingwersen/Desktop/fileshare/out/excel/out_interactive.xlsm\")\n",
    "sheet = wb.sheets['Inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da2f2a440efe17b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T04:24:42.093543Z",
     "start_time": "2024-08-30T04:24:41.844877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>yard</th>\n",
       "      <th>weightIni</th>\n",
       "      <th>Fe</th>\n",
       "      <th>SiO2</th>\n",
       "      <th>Al2O3</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60000</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>45000</td>\n",
       "      <td>76.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100000</td>\n",
       "      <td>87.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>50000</td>\n",
       "      <td>56.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>60000</td>\n",
       "      <td>70.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>75000</td>\n",
       "      <td>65.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>40000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>45000</td>\n",
       "      <td>60.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>68.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>55000</td>\n",
       "      <td>72.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>45000</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>47500</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>52500</td>\n",
       "      <td>64.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>55000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>57500</td>\n",
       "      <td>62.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>60000</td>\n",
       "      <td>66.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>62500</td>\n",
       "      <td>68.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>65000</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>67500</td>\n",
       "      <td>69.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>70000</td>\n",
       "      <td>65.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  yard  weightIni    Fe  SiO2  Al2O3     P\n",
       "0    1     1      60000  10.3   2.3    4.5  0.05\n",
       "1    2     1      45000  76.3   5.6    4.8  0.05\n",
       "2    3     2     100000  87.3   3.7    5.0  0.05\n",
       "3    4     2      50000  56.3   3.8    5.3  0.09\n",
       "4    5     3      60000  70.5   4.0    5.1  0.07\n",
       "5    6     3      75000  65.4   4.5    4.9  0.06\n",
       "6    7     4      40000  75.0   4.3    5.0  0.08\n",
       "7    8     4      45000  60.3   5.5    4.7  0.06\n",
       "8    9     5      50000  68.3   3.2    4.8  0.07\n",
       "9   10     5      55000  72.1   3.5    5.2  0.09\n",
       "10  11     6      45000  65.2   4.1    4.9  0.05\n",
       "11  12     6      47500  67.8   3.8    5.1  0.06\n",
       "12  13     7      52500  64.3   4.3    5.3  0.07\n",
       "13  14     7      55000  63.0   4.0    5.5  0.08\n",
       "14  15     8      57500  62.7   4.2    5.4  0.09\n",
       "15  16     8      60000  66.5   3.7    5.0  0.05\n",
       "16  17     9      62500  68.1   3.6    4.8  0.06\n",
       "17  18     9      65000  67.0   3.9    4.9  0.07\n",
       "18  19    10      67500  69.4   4.0    5.1  0.08\n",
       "19  20    10      70000  65.9   4.4    5.2  0.09"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9709d6cf8e24d8da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T04:38:05.540969Z",
     "start_time": "2024-08-30T04:38:04.931925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>yard</th>\n",
       "      <th>weightIni</th>\n",
       "      <th>Fe</th>\n",
       "      <th>SiO2</th>\n",
       "      <th>Al2O3</th>\n",
       "      <th>P</th>\n",
       "      <th>rails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60000</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>45000</td>\n",
       "      <td>76.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100000</td>\n",
       "      <td>87.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>50000</td>\n",
       "      <td>56.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>60000</td>\n",
       "      <td>70.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>75000</td>\n",
       "      <td>65.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>40000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>45000</td>\n",
       "      <td>60.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.06</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>68.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.07</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>55000</td>\n",
       "      <td>72.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>45000</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>47500</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>52500</td>\n",
       "      <td>64.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.07</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>55000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>57500</td>\n",
       "      <td>62.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>60000</td>\n",
       "      <td>66.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>62500</td>\n",
       "      <td>68.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>65000</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>67500</td>\n",
       "      <td>69.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>70000</td>\n",
       "      <td>65.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  yard  weightIni    Fe  SiO2  Al2O3     P   rails\n",
       "0    1     1      60000  10.3   2.3    4.5  0.05  [1, 2]\n",
       "1    2     1      45000  76.3   5.6    4.8  0.05  [1, 2]\n",
       "2    3     2     100000  87.3   3.7    5.0  0.05     [2]\n",
       "3    4     2      50000  56.3   3.8    5.3  0.09     [2]\n",
       "4    5     3      60000  70.5   4.0    5.1  0.07  [1, 2]\n",
       "5    6     3      75000  65.4   4.5    4.9  0.06  [1, 2]\n",
       "6    7     4      40000  75.0   4.3    5.0  0.08     [2]\n",
       "7    8     4      45000  60.3   5.5    4.7  0.06     [2]\n",
       "8    9     5      50000  68.3   3.2    4.8  0.07  [1, 2]\n",
       "9   10     5      55000  72.1   3.5    5.2  0.09  [1, 2]\n",
       "10  11     6      45000  65.2   4.1    4.9  0.05  [1, 2]\n",
       "11  12     6      47500  67.8   3.8    5.1  0.06  [1, 2]\n",
       "12  13     7      52500  64.3   4.3    5.3  0.07  [1, 2]\n",
       "13  14     7      55000  63.0   4.0    5.5  0.08  [1, 2]\n",
       "14  15     8      57500  62.7   4.2    5.4  0.09  [1, 2]\n",
       "15  16     8      60000  66.5   3.7    5.0  0.05  [1, 2]\n",
       "16  17     9      62500  68.1   3.6    4.8  0.06  [1, 2]\n",
       "17  18     9      65000  67.0   3.9    4.9  0.07  [1, 2]\n",
       "18  19    10      67500  69.4   4.0    5.1  0.08  [1, 2]\n",
       "19  20    10      70000  65.9   4.4    5.2  0.09  [1, 2]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockpiles = sheet['D2'].options(pd.DataFrame, expand='table').value.reset_index()\n",
    "rename_dict = {\n",
    "    \"ID\": \"id\",\n",
    "    \"Área\": \"yard\",\n",
    "    \"Quantidade (ton)\": \"weightIni\"\n",
    "}\n",
    "stockpiles = stockpiles.rename(columns=rename_dict).astype({col: int for col in rename_dict.values()})\n",
    "\n",
    "yards = sheet['L2'].options(pd.DataFrame, expand='table').value.reset_index()\n",
    "\n",
    "engine_cols = [col for col in yards.columns if any(ch.isnumeric() for ch in col)]\n",
    "rename_dict = {\n",
    "    col: \"\".join(ch for ch in col if ch.isnumeric())\n",
    "    for col in engine_cols\n",
    "}\n",
    "engine_ids = list(rename_dict.values())\n",
    "yards = yards.rename(columns=rename_dict).astype({\"yard\": int})\n",
    "yards[\"rails\"] = yards[engine_ids].apply(\n",
    "    lambda row: [idx for idx, value in enumerate(row, 1) if pd.notna(value)], \n",
    "    axis=1\n",
    ")\n",
    "yards = yards.drop(columns=engine_ids)\n",
    "\n",
    "stockpiles = stockpiles.merge(yards, on=\"yard\", how=\"left\")\n",
    "stockpiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82dbe103b41cafc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T04:39:23.571970Z",
     "start_time": "2024-08-30T04:39:23.365676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>speedReclaim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  speedReclaim\n",
       "0   1          3900\n",
       "1   2          2600"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engines = sheet['P2'].options(pd.DataFrame, expand='table').value.reset_index()\n",
    "engines = engines.rename(columns={\"Veículo\": \"id\", \"Taxa (ton/min)\": \"speedReclaim\"}).astype(int)\n",
    "engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "836de181405351e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T05:00:01.146438Z",
     "start_time": "2024-08-30T05:00:00.929679Z"
    }
   },
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    \"De\": \"from\",\n",
    "    \"Para\": \"to\",\n",
    "}\n",
    "travel_speed = sheet['S2'].options(pd.DataFrame, expand='table').value.reset_index()\n",
    "travel_speed = travel_speed.rename(columns=rename_dict)\n",
    "stockpiles_from_to_cols = list(rename_dict.values())\n",
    "speed_cols = travel_speed.columns.difference(stockpiles_from_to_cols)\n",
    "travel_speed[\"travel_time\"] = travel_speed[speed_cols[0]]\n",
    "for col in speed_cols[1:]:\n",
    "    travel_speed[\"travel_time\"] = travel_speed[\"travel_time\"].fillna(travel_speed[col])\n",
    "\n",
    "travel_speed = travel_speed.drop(columns=speed_cols)\n",
    "travel_times = travel_speed.pivot_table(index=[\"from\"], columns=[\"to\"], values=[\"travel_time\"]).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "567be8c718a54c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T04:59:47.048651Z",
     "start_time": "2024-08-30T04:59:46.882092Z"
    }
   },
   "outputs": [],
   "source": [
    "output_info = sheet[\"A2\"].options(pd.DataFrame, expand='table').value.reset_index()\n",
    "\n",
    "outputs = [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"destination\": 1,\n",
    "      \"weight\": int(output_info.iloc[0, 1]),\n",
    "      \"quality\": [\n",
    "        {\n",
    "          \"parameter\": \"Fe\",\n",
    "          \"minimum\": 60,\n",
    "          \"maximum\": 100,\n",
    "          \"goal\": 65,\n",
    "          \"importance\": 10\n",
    "        },\n",
    "        {\n",
    "          \"parameter\": \"SiO2\",\n",
    "          \"minimum\": 2.8,\n",
    "          \"maximum\": 5.8,\n",
    "          \"goal\": 5.8,\n",
    "          \"importance\": 1000\n",
    "        },\n",
    "        {\n",
    "          \"parameter\": \"Al2O3\",\n",
    "          \"minimum\": 2.5,\n",
    "          \"maximum\": 4.9,\n",
    "          \"goal\": 4.9,\n",
    "          \"importance\": 100\n",
    "        },\n",
    "        {\n",
    "          \"parameter\": \"P\",\n",
    "          \"minimum\": 0.05,\n",
    "          \"maximum\": 0.07,\n",
    "          \"goal\": 0.07,\n",
    "          \"importance\": 100\n",
    "        }\n",
    "      ],\n",
    "      \"time\": 600\n",
    "    }\n",
    "]\n",
    "inputs = [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"weight\": 0.0,\n",
    "      \"quality\": [\n",
    "        {\n",
    "          \"parameter\": \"Fe\",\n",
    "          \"value\": 60\n",
    "        },\n",
    "        {\n",
    "          \"parameter\": \"SiO2\",\n",
    "          \"value\": 1.5\n",
    "        },\n",
    "        {\n",
    "          \"parameter\": \"Al2O3\",\n",
    "          \"value\": 0.8\n",
    "        },\n",
    "        {\n",
    "          \"parameter\": \"P\",\n",
    "          \"value\": 1.0\n",
    "        }\n",
    "      ],\n",
    "      \"time\": 8.0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20152df3973ca3a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T05:02:53.335837Z",
     "start_time": "2024-08-30T05:02:53.328669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(travel_times[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bcfdd80f3f530fbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T05:03:37.234517Z",
     "start_time": "2024-08-30T05:03:37.223640Z"
    }
   },
   "outputs": [],
   "source": [
    "instance_data = {\n",
    "    \"info\": [\"Instance_Interactive\", 1000, 1],\n",
    "    \"stockpiles\": [],\n",
    "    \"engines\": [],\n",
    "    \"inputs\": inputs,\n",
    "    \"outputs\": outputs,\n",
    "    \"distancesTravel\": travel_times,\n",
    "    \"timeTravel\": travel_times\n",
    "}\n",
    "for _, row in stockpiles.iterrows():\n",
    "    sp = {\n",
    "        \"id\": int(row[\"id\"]),\n",
    "        \"position\": int(row[\"id\"]) - 1,\n",
    "        \"yard\": int(row[\"yard\"]),\n",
    "        \"rails\": [int(r) for r in row[\"rails\"]],\n",
    "        \"capacity\": int(row[\"weightIni\"]),\n",
    "        \"weightIni\": int(row[\"weightIni\"]),\n",
    "        \"qualityIni\": [\n",
    "            {\"parameter\": \"Fe\", \"value\": float(row[\"Fe\"])},\n",
    "            {\"parameter\": \"SiO2\", \"value\": float(row[\"SiO2\"])},\n",
    "            {\"parameter\": \"Al2O3\", \"value\": float(row[\"Al2O3\"])},\n",
    "            {\"parameter\": \"P\", \"value\": float(row[\"P\"])}\n",
    "        ]\n",
    "    }\n",
    "    instance_data[\"stockpiles\"].append(sp)\n",
    "\n",
    "all_yards = [int(y) for y in stockpiles[\"yard\"].drop_duplicates().to_list()]\n",
    "for _, row in engines.iterrows():\n",
    "    eng = {\n",
    "      \"id\": int(row[\"id\"]),\n",
    "      \"speedStack\": 0.0,\n",
    "      \"speedReclaim\": int(row[\"speedReclaim\"]),\n",
    "      \"posIni\": int(row[\"id\"]),\n",
    "      \"rail\": int(row[\"id\"]),\n",
    "      \"yards\": all_yards\n",
    "    }\n",
    "    instance_data[\"engines\"].append(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1be75b89f9a75771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T05:03:37.769650Z",
     "start_time": "2024-08-30T05:03:37.763823Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write the data to the JSON file\n",
    "with open('../tests/instance_11.json', 'w') as json_file:\n",
    "    json.dump(instance_data, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T00:34:35.456218Z",
     "start_time": "2024-08-30T00:34:35.438605Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def export_to_json():\n",
    "    # Open the workbook and select the Inputs sheet\n",
    "    wb = xw.Book.caller()  # Connect to the workbook that called this function\n",
    "    sheet = wb.sheets['Inputs']\n",
    "\n",
    "    # Initialize instance data\n",
    "    instance_data = {\n",
    "        \"info\": [\"Instance_Interactive\", 1000, 1],\n",
    "        \"stockpiles\": [],\n",
    "        \"engines\": [],\n",
    "        \"inputs\": [],\n",
    "        \"outputs\": [],\n",
    "        \"distancesTravel\": travel_times,\n",
    "        \"timeTravel\": travel_times\n",
    "    }\n",
    "\n",
    "    # Read Stockpiles data\n",
    "    row = 3  # Starting row for stockpiles, adjust if necessary\n",
    "    while sheet.range(f\"D{row}\").value:\n",
    "        stockpile = {\n",
    "            \"id\": int(sheet.range(f\"D{row}\").value),\n",
    "            \"position\": int(sheet.range(f\"D{row}\").value - 1),\n",
    "            \"yard\": int(sheet.range(f\"E{row}\").value),\n",
    "            \"rails\": [1, 2],\n",
    "            \"capacity\": int(sheet.range(f\"F{row}\").value),\n",
    "            \"weightIni\": int(sheet.range(f\"F{row}\").value),\n",
    "            \"qualityIni\": [\n",
    "                {\"parameter\": \"Fe\", \"value\": float(sheet.range(f\"G{row}\").value)},\n",
    "                {\"parameter\": \"SiO2\", \"value\": float(sheet.range(f\"H{row}\").value)},\n",
    "                {\"parameter\": \"Al2O3\", \"value\": float(sheet.range(f\"I{row}\").value)},\n",
    "                {\"parameter\": \"P\", \"value\": float(sheet.range(f\"J{row}\").value)}\n",
    "            ]\n",
    "        }\n",
    "        instance_data[\"stockpiles\"].append(stockpile)\n",
    "        row += 1\n",
    "\n",
    "    # Read Engines data\n",
    "    row = 3  # Adjust if necessary, find the first row of engines data\n",
    "    engine_ids = sheet.range(f\"P{row}:P{row+2}\").value  # Assuming up to 20 rows\n",
    "    speed_reclaims = sheet.range(f\"Q{row}:Q{row+2}\").value\n",
    "\n",
    "    yards = {engine_id: [] for engine_id in engine_ids}\n",
    "\n",
    "    while sheet.range(f\"L{row}\").value:\n",
    "        # Find the yards accessible by the engine\n",
    "        if sheet.range(f\"M{row}\").value == \"x\":\n",
    "            yards[engine_ids[0]].append(sheet.range(f\"L{row}\").value)\n",
    "        if sheet.range(f\"N{row}\").value == \"x\":\n",
    "            yards[engine_ids[1]].append(sheet.range(f\"L{row}\").value)\n",
    "\n",
    "    for engine_id, speed_reclaim in zip(engine_ids, speed_reclaims):\n",
    "        engine_yards = yards[engine_id]\n",
    "        for stockpile in instance_data[\"stockpiles\"]:\n",
    "            if stockpile[\"yard\"] in engine_yards:\n",
    "                posIni = stockpile[\"id\"]\n",
    "                break\n",
    "\n",
    "        engine = {\n",
    "            \"id\": int(engine_id),\n",
    "            \"speedStack\": 0.0,\n",
    "            \"speedReclaim\": speed_reclaim,\n",
    "            \"posIni\": posIni,  # Set to first stockpile ID if any yards\n",
    "            \"rail\": [1, 2],  # Assuming rail is in column O\n",
    "            \"yards\": engine_yards\n",
    "        }\n",
    "        instance_data[\"engines\"].append(engine)\n",
    "\n",
    "    # Read the Inputs section similarly if needed\n",
    "    \n",
    "    # Read Time Travel and Distances Travel data\n",
    "    # Assuming these columns have a consistent number of rows as stockpiles\n",
    "    row = 3  # Start row for stockpiles\n",
    "    times = []\n",
    "    while sheet.range(f\"S{row}\").value:\n",
    "        time_row = [sheet.range(f\"S{row}\").value, sheet.range(f\"T{row}\").value]\n",
    "        time_row.extend([sheet.range(f\"U{row}\").value, sheet.range(f\"V{row}\").value])\n",
    "        times.append([t for t in time_row if t is not None])  # Removing None values\n",
    "        row += 1\n",
    "\n",
    "    # Fill timeTravel and distancesTravel with the same matrix\n",
    "    instance_data[\"timeTravel\"] = times\n",
    "    instance_data[\"distancesTravel\"] = times\n",
    "\n",
    "    # Write the data to the JSON file\n",
    "    with open('instance_9.json', 'w') as json_file:\n",
    "        json.dump(instance_data, json_file, indent=2)\n",
    "\n",
    "    xw.alert('JSON file created successfully!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be5cb9ca630af316",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T00:39:35.089671Z",
     "start_time": "2024-08-30T00:38:02.360093Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m xw\u001b[38;5;241m.\u001b[39mBook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/erikingwersen/Desktop/fileshare/out/excel/out_interactive.xlsm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mset_mock_caller()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mexport_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 48\u001b[0m, in \u001b[0;36mexport_to_json\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sheet\u001b[38;5;241m.\u001b[39mrange(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     47\u001b[0m         yards[engine_ids[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mappend(sheet\u001b[38;5;241m.\u001b[39mrange(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msheet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mN\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrow\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     49\u001b[0m         yards[engine_ids[\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m.\u001b[39mappend(sheet\u001b[38;5;241m.\u001b[39mrange(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m engine_id, speed_reclaim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(engine_ids, speed_reclaims):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyBlend/lib/python3.10/site-packages/xlwings/main.py:2474\u001b[0m, in \u001b[0;36mRange.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2462\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2465\u001b[0m \u001b[38;5;124;03m    Gets and sets the values for the given Range. See :meth:`xlwings.Range.options`\u001b[39;00m\n\u001b[1;32m   2466\u001b[0m \u001b[38;5;124;03m    about how to set options, e.g., to transform it into a DataFrame or how to set\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[38;5;124;03m             see :meth:`xlwings.Range.options`\u001b[39;00m\n\u001b[1;32m   2473\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyBlend/lib/python3.10/site-packages/xlwings/conversion/__init__.py:77\u001b[0m, in \u001b[0;36mread\u001b[0;34m(rng, value, options, engine_name)\u001b[0m\n\u001b[1;32m     75\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m accessors\u001b[38;5;241m.\u001b[39mget(convert, convert)\u001b[38;5;241m.\u001b[39mreader(options)\n\u001b[1;32m     76\u001b[0m ctx \u001b[38;5;241m=\u001b[39m ConversionContext(rng\u001b[38;5;241m=\u001b[39mrng, value\u001b[38;5;241m=\u001b[39mvalue, engine_name\u001b[38;5;241m=\u001b[39mengine_name)\n\u001b[0;32m---> 77\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xw.Book(\"/Users/erikingwersen/Desktop/fileshare/out/excel/out_interactive.xlsm\").set_mock_caller()\n",
    "export_to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bcf7c54c9167c3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T09:20:14.268741Z",
     "iopub.status.busy": "2024-08-30T09:20:14.268286Z",
     "iopub.status.idle": "2024-08-30T09:20:14.344811Z",
     "shell.execute_reply": "2024-08-30T09:20:14.342545Z",
     "shell.execute_reply.started": "2024-08-30T09:20:14.268708Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List, Dict, Any\n",
    "import subprocess\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xlwings as xw\n",
    "\n",
    "\n",
    "def check_is_file(*filepaths):\n",
    "    files_not_found = []\n",
    "    for filepath in filepaths:\n",
    "        _filepath = Path(filepath)\n",
    "        if not _filepath.is_file():\n",
    "            files_not_found.append(filepath)\n",
    "    if len(files_not_found) > 0:\n",
    "        plural = \"\" if len(files_not_found) == 1 else \"s\"\n",
    "        past_tense_form = \"was\" if len(files_not_found) == 1 else \"were\"\n",
    "        exception_message = (\n",
    "            f\"The following file{plural} {past_tense_form}n't found: \"\n",
    "            + \", \".join(files_not_found)\n",
    "        )\n",
    "        raise FileNotFoundError(exception_message)\n",
    "\n",
    "\n",
    "# Helper function to autofit column widths with a minimum width\n",
    "def autofit_columns(ws):\n",
    "    for col in ws.columns:\n",
    "        max_length = 0\n",
    "        column = col[0].column_letter  # Get the column name\n",
    "        for cell in col:\n",
    "            if cell.value:\n",
    "                max_length = max(max_length, len(str(cell.value)))\n",
    "        adjusted_width = max(max_length + 2, 10)  # Minimum width set to 10\n",
    "        ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "\n",
    "# Convert input and output JSON files to dataframes\n",
    "def explode_quality_rows(\n",
    "    df: pd.DataFrame,\n",
    "    quality_col_prefix: str = \"quality_\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Explode the `'quality_*'` columns into rows.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe with the output specifications with the quality columns\n",
    "        that contain dictionaries of quality parameters to be extracted.\n",
    "    quality_col_prefix : str, default='quality_'\n",
    "        The prefix of the quality columns that contain the output pile specifications\n",
    "        that need to be extracted into different columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The `pandas.DataFrame` with the quality dictionaries extracted into\n",
    "        new columns.\n",
    "    \"\"\"\n",
    "    # Create a new DataFrame to store exploded rows\n",
    "    exploded_df = pd.DataFrame()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        quality_dict_list = [\n",
    "            value for key, value in row.items() if key.startswith(quality_col_prefix)\n",
    "        ]\n",
    "\n",
    "        # Convert the list of quality dictionaries into a DataFrame\n",
    "        quality_df = pd.DataFrame(quality_dict_list)\n",
    "\n",
    "        # Repeat the original columns for each exploded row\n",
    "        repeated_columns = pd.DataFrame(\n",
    "            [\n",
    "                row.drop(\n",
    "                    labels=[\n",
    "                        col for col in df.columns if col.startswith(quality_col_prefix)\n",
    "                    ]\n",
    "                )\n",
    "            ]\n",
    "            * len(quality_df)\n",
    "        )\n",
    "\n",
    "        # Concatenate the repeated columns with the quality columns\n",
    "        exploded_row_df = pd.concat(\n",
    "            [\n",
    "                repeated_columns.reset_index(drop=True),\n",
    "                quality_df.reset_index(drop=True),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        # Append to the exploded DataFrame\n",
    "        exploded_df = pd.concat([exploded_df, exploded_row_df], ignore_index=True)\n",
    "\n",
    "    return exploded_df\n",
    "\n",
    "\n",
    "def assign_engines_to_stockpiles(\n",
    "    stockpiles_df: pd.DataFrame, engines_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assign engines to stockpiles based on matching yards and rails.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stockpiles_df : pd.DataFrame\n",
    "        A `pandas.DataFrame` containing stockpile information including\n",
    "        'rails' and 'yard'.\n",
    "    engines_df : pd.DataFrame\n",
    "        A `pandas.DataFrame` containing engine information including 'yards' and 'rail'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Updated `stockpiles_df` with an 'engines' column listing the assigned engine IDs.\n",
    "    \"\"\"\n",
    "    stockpiles_df[\"engines\"] = [[] for _ in range(stockpiles_df.shape[0])]\n",
    "\n",
    "    for idx, stockpile in stockpiles_df.iterrows():\n",
    "        assigned_engines = [\n",
    "            eng_row[\"id\"]\n",
    "            for _, eng_row in engines_df.iterrows()\n",
    "            if stockpile[\"yard\"] in eng_row[\"yards\"]\n",
    "            and eng_row[\"rail\"] in stockpile[\"rails\"]\n",
    "        ]\n",
    "        stockpiles_df.at[idx, \"engines\"] = assigned_engines\n",
    "\n",
    "    return stockpiles_df\n",
    "\n",
    "\n",
    "def extract_quality_ini_values(\n",
    "    stockpiles_df: pd.DataFrame, quality_prefix: str = \"qualityIni\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract initial quality values from nested dictionaries in the stockpiles DataFrame\n",
    "    and add them as new columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stockpiles_df : pd.DataFrame\n",
    "        A `pandas.DataFrame` containing stockpile information, including quality parameters.\n",
    "    quality_prefix : str, default='qualityIni'\n",
    "        Prefix used in column names for quality-related information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Updated `stockpiles_df` with quality parameters extracted as individual columns.\n",
    "    \"\"\"\n",
    "    quality_cols = stockpiles_df.columns[\n",
    "        stockpiles_df.columns.str.startswith(quality_prefix)\n",
    "    ]\n",
    "    quality_ini_dict = {}\n",
    "\n",
    "    for column in quality_cols:\n",
    "        for idx, row in stockpiles_df.iterrows():\n",
    "            parameter = row[column][\"parameter\"]\n",
    "            value = row[column][\"value\"]\n",
    "            quality_ini_dict.setdefault(parameter, []).append(value)\n",
    "\n",
    "    # Add the extracted quality values as new columns and drop the original quality columns\n",
    "    stockpiles_df = pd.concat(\n",
    "        [stockpiles_df, pd.DataFrame(quality_ini_dict, index=stockpiles_df.index)],\n",
    "        axis=1,\n",
    "    ).drop(columns=quality_cols, errors=\"ignore\")\n",
    "\n",
    "    return stockpiles_df\n",
    "\n",
    "\n",
    "def process_stockpiles_and_engines(\n",
    "    stockpiles_df: pd.DataFrame, engines_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process stockpiles and engines by assigning engines to stockpiles and extracting initial quality values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stockpiles_df : pd.DataFrame\n",
    "        A `pandas.DataFrame` containing stockpile information.\n",
    "    engines_df : pd.DataFrame\n",
    "        A `pandas.DataFrame` containing engine information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Processed `stockpiles_df` with engines assigned and quality values extracted.\n",
    "    \"\"\"\n",
    "    stockpiles_df = assign_engines_to_stockpiles(stockpiles_df, engines_df)\n",
    "    stockpiles_df = extract_quality_ini_values(stockpiles_df)\n",
    "    return stockpiles_df\n",
    "\n",
    "\n",
    "def travel_time(grp: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the travel time between consecutive events within a group.\n",
    "\n",
    "    This function calculates the time between the end of one event and the start of the next event\n",
    "    within a grouped DataFrame. If the group contains only one event, the travel time is set to 0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    grp : pd.DataFrame\n",
    "        A `pandas.DataFrame` containing at least 'start_time' and 'end_time'\n",
    "        columns. The DataFrame is expected to be pre-grouped by a relevant key\n",
    "        before being passed to this function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A `pandas.DataFrame` with a single column 'travel_time',\n",
    "        containing the calculated travel times between consecutive events.\n",
    "        The index of the returned DataFrame matches the input DataFrame.\n",
    "    \"\"\"\n",
    "    if len(grp) == 1:\n",
    "        return pd.DataFrame(\n",
    "            {\"travel_time\": [grp[\"start_time\"].values[0]]}, index=grp.index\n",
    "        )\n",
    "    grp = grp.sort_values([\"end_time\"])\n",
    "    end_time = None\n",
    "    res = []\n",
    "    for _, row in grp.iterrows():\n",
    "        _end_time = row[\"end_time\"]\n",
    "        if end_time is None:\n",
    "            res.append(row[\"start_time\"])\n",
    "        else:\n",
    "            res.append(row[\"start_time\"] - end_time)\n",
    "        end_time = _end_time\n",
    "    return pd.DataFrame({\"travel_time\": res}, index=grp.index)\n",
    "\n",
    "\n",
    "def json_input_output_to_excel(\n",
    "    json_input_path: str | Path,\n",
    "    json_output_path: str | Path,\n",
    "    excel_path: str | Path | None = None,\n",
    "):\n",
    "    check_is_file(json_input_path, json_output_path)\n",
    "    \n",
    "    if excel_path is None:\n",
    "        excel_filename = Path(json_output_path).with_suffix(\".xlsx\").name\n",
    "        excel_folder_path = Path(json_output_path).parent.parent.joinpath(\"excel\")\n",
    "        excel_path = str(excel_folder_path.joinpath(excel_filename))\n",
    "    else:\n",
    "        excel_folder_path = Path(excel_path).parent\n",
    "\n",
    "    excel_folder_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # Load JSON files\n",
    "    # Input file\n",
    "    with open(json_input_path) as fh:\n",
    "        instance_data = json.load(fh)\n",
    "    \n",
    "    # Output file\n",
    "    with open(json_output_path) as fh:\n",
    "        output_data = json.load(fh)\n",
    "    \n",
    "    info_df = pd.DataFrame([instance_data[\"info\"]], columns=[\"Instance_Name\", \"Capacity\", \"Yard\"])\n",
    "    engines_df = pd.DataFrame(instance_data[\"engines\"])\n",
    "    stockpiles_df = pd.DataFrame(instance_data[\"stockpiles\"])\n",
    "    stockpiles_quality_df = pd.json_normalize(stockpiles_df.pop(\"qualityIni\"), sep=\"_\").add_prefix(\"qualityIni_\")\n",
    "    stockpiles_df = pd.concat([stockpiles_df, stockpiles_quality_df], axis=1)\n",
    "    stockpiles_df = process_stockpiles_and_engines(stockpiles_df, engines_df)\n",
    "    \n",
    "    inputs_df = pd.DataFrame(instance_data[\"inputs\"])\n",
    "    inputs_quality_df = pd.json_normalize(inputs_df.pop(\"quality\"), sep=\"_\").add_prefix(\"quality_\")\n",
    "    inputs_df = pd.concat([inputs_df, inputs_quality_df], axis=1)\n",
    "    \n",
    "    # Convert instance_1.json to DataFrames\n",
    "    outputs_df = pd.DataFrame(instance_data[\"outputs\"])\n",
    "    outputs_quality_df = pd.json_normalize(outputs_df.pop(\"quality\"), sep=\"_\").add_prefix(\"quality_\")\n",
    "    outputs_df = pd.concat([outputs_df, outputs_quality_df], axis=1)\n",
    "    \n",
    "    # Explode the outputs_df\n",
    "    outputs_df = explode_quality_rows(outputs_df, quality_col_prefix=\"quality_\").drop(\n",
    "        columns=[\"time\"], errors=\"ignore\"\n",
    "    )\n",
    "    distances_travel_df = pd.DataFrame(instance_data[\"distancesTravel\"])\n",
    "    time_travel_df = pd.DataFrame(instance_data[\"timeTravel\"])\n",
    "    \n",
    "    time_travel_df.columns += 1\n",
    "    time_travel_df.index += 1\n",
    "    \n",
    "    distances_travel_df.columns += 1\n",
    "    distances_travel_df.index += 1\n",
    "    \n",
    "    from_to_list = []\n",
    "    for col in time_travel_df.columns:\n",
    "        for idx in time_travel_df.index:\n",
    "            from_to_list.append([f\"{col} -> {idx}\", time_travel_df.loc[idx, col]])\n",
    "    from_to_df = pd.DataFrame(from_to_list, columns=[\"from_to\", \"duration\"])\n",
    "    \n",
    "    engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
    "    engines_df[from_to_df[\"from_to\"].to_list()] = engines_df[from_to_df[\"from_to\"].to_list()].astype(float)\n",
    "    \n",
    "    for idx, row in engines_df.iterrows():\n",
    "        yards = row[\"yards\"]\n",
    "        rail = row[\"rail\"]\n",
    "        stockpiles = []\n",
    "        for _, stockpile_row in stockpiles_df.iterrows():\n",
    "            if stockpile_row[\"yard\"] in yards and rail in stockpile_row[\"rails\"]:\n",
    "                stockpiles.append(stockpile_row[\"id\"])\n",
    "        for start_stockpile in stockpiles:\n",
    "            for end_stockpile in stockpiles:\n",
    "                column_name = f\"{start_stockpile} -> {end_stockpile}\"\n",
    "                duration = from_to_df.loc[\n",
    "                    from_to_df[\"from_to\"] == column_name, \"duration\"\n",
    "                ].values[0]\n",
    "                engines_df.loc[engines_df.index == idx, column_name] = duration\n",
    "    \n",
    "    engines_df[from_to_df[\"from_to\"].to_list()] = engines_df[from_to_df[\"from_to\"].to_list()].replace(-1, \"\")\n",
    "    \n",
    "    objective_df = pd.DataFrame([{\"Objective\": output_data[\"objective\"], \"Gap\": output_data[\"gap\"][0]}])\n",
    "    stacks_df = pd.DataFrame(output_data[\"stacks\"])\n",
    "    reclaims_df = pd.DataFrame(output_data[\"reclaims\"])\n",
    "    \n",
    "    outputs_df_out = pd.DataFrame(output_data[\"outputs\"])\n",
    "    outputs_quality_df_out = pd.json_normalize(outputs_df_out.pop(\"quality\"), sep=\"_\").add_prefix(\"quality_\")\n",
    "    \n",
    "    outputs_df_out = pd.concat([outputs_df_out, outputs_quality_df_out], axis=1)\n",
    "    outputs_df_out = explode_quality_rows(outputs_df_out, quality_col_prefix=\"quality_\")\n",
    "    \n",
    "    if not stacks_df.empty:\n",
    "        stacks_df[\"end_time\"] = stacks_df[\"start_time\"] + stacks_df[\"duration\"]\n",
    "        stacks_df[\"operation\"] = \"stack\"\n",
    "    \n",
    "    if not reclaims_df.empty:\n",
    "        reclaims_df[\"end_time\"] = reclaims_df[\"start_time\"] + reclaims_df[\"duration\"]\n",
    "        reclaims_df[\"operation\"] = \"reclaim\"\n",
    "    \n",
    "    operations_df = (\n",
    "        pd.concat([xdf for xdf in [stacks_df, reclaims_df] if not xdf.empty])\n",
    "        .astype({\"weight\": int})\n",
    "        .sort_values([\"engine\", \"start_time\"])\n",
    "        .assign(\n",
    "            travel_time=lambda xdf: (\n",
    "                xdf.groupby(\"engine\", as_index=False).apply(travel_time)\n",
    "            )[\"travel_time\"].reset_index(level=0, drop=True)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    stockpiles_final_df = (\n",
    "        stockpiles_df.merge(\n",
    "            operations_df.rename(columns={\"weight\": \"weightFinal\"})\n",
    "            .groupby(\"stockpile\")[\"weightFinal\"]\n",
    "            .sum(),\n",
    "            left_on=\"id\",\n",
    "            right_index=True,\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .fillna({\"weightFinal\": 0})\n",
    "        .astype({\"weightFinal\": int})\n",
    "        .assign(weightFinal=lambda xdf: xdf[\"weightIni\"] - xdf[\"weightFinal\"])\n",
    "    )\n",
    "    \n",
    "    quality_cols = stockpiles_df.columns.intersection([\"Fe\", \"SiO2\", \"Al2O3\", \"P\", \"+31.5\", \"-6.3\"]).to_list()\n",
    "    \n",
    "    operations_df = operations_df.merge(\n",
    "        stockpiles_df.rename(columns={\"id\": \"stockpile\"})[[\"stockpile\", \"weightIni\", *quality_cols]],\n",
    "        on=\"stockpile\",\n",
    "        how=\"left\",\n",
    "    ).assign(weightFinal=lambda xdf: xdf[\"weightIni\"] - xdf[\"weight\"])\n",
    "    \n",
    "    final_output_row = [\n",
    "        operations_df[\"weight\"].sum(),\n",
    "        \"output\",\n",
    "        operations_df[\"engine\"].unique().tolist(),\n",
    "        operations_df[\"start_time\"].min(),\n",
    "        operations_df[\"end_time\"].max(),\n",
    "        1,\n",
    "        operations_df[\"end_time\"].max(),\n",
    "        \"output_stack\",\n",
    "        operations_df[\"travel_time\"].sum(),\n",
    "        operations_df[\"weightFinal\"].sum(),\n",
    "    ]\n",
    "    \n",
    "    for quality_col in quality_cols:\n",
    "        final_output_row.append(\n",
    "            (\n",
    "                (\n",
    "                    operations_df[\"weight\"]\n",
    "                    * operations_df[quality_col]\n",
    "                    / operations_df[\"weight\"].sum()\n",
    "                ).sum()\n",
    "            )\n",
    "        )\n",
    "    operations_df = pd.concat(\n",
    "        [\n",
    "            operations_df,\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    col: [value]\n",
    "                    for col, value in zip(operations_df.columns, final_output_row)\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "    \n",
    "    required_weight = operations_df.loc[operations_df[\"stockpile\"] == \"output\", \"weight\"].values[0]\n",
    "    infos_gerais = pd.DataFrame(\n",
    "        {\n",
    "            \"Variável\": [\"Peso Carregamento\"],\n",
    "            \"Valor\": [required_weight]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    engines_yards = (\n",
    "        stockpiles_final_df[[\"yard\", \"engines\"]]\n",
    "        .astype({\"engines\": str})\n",
    "        .drop_duplicates()\n",
    "        .assign(\n",
    "            engines=lambda xdf: xdf[\"engines\"]\n",
    "            .str.replace(\"[\", \"\")\n",
    "            .str.replace(\"]\", \"\")\n",
    "            .str.replace(\" \", \"\")\n",
    "            .str.replace(\",\", \"\")\n",
    "            .apply(list)\n",
    "        )\n",
    "    )\n",
    "    all_engines = list(\n",
    "        sorted(set([engine for engines in engines_yards[\"engines\"] for engine in engines]))\n",
    "    )\n",
    "    for engine in all_engines:\n",
    "        engines_yards[f\"Veículo {engine}\"] = engines_yards[\"engines\"].apply(lambda value: \"x\" if engine in value else \"\")\n",
    "    \n",
    "    engines_yards = engines_yards.drop(columns=[\"engines\"]).rename({\"yard\": \"Área\"})\n",
    "    \n",
    "    rename_dict = {\n",
    "        \"id\": \"ID\",\n",
    "        \"yard\": \"Área\",\n",
    "        \"weightIni\": \"Quantidade (ton)\",\n",
    "    }\n",
    "    final_cols = [*list(rename_dict.values()), *quality_cols]\n",
    "    stockpiles_final_df = stockpiles_final_df.rename(columns=rename_dict)[final_cols]\n",
    "    \n",
    "    load_rates = (\n",
    "        engines_df[[\"id\", \"speedReclaim\"]]\n",
    "        .astype({\"speedReclaim\": int})\n",
    "        .rename(columns={\"id\": \"Veículo\", \"speedReclaim\": \"Taxa (ton/min)\"})\n",
    "    )\n",
    "    \n",
    "    from_to_cols = [col for col in engines_df.columns if \"->\" in col]\n",
    "    travel_times_dict = {\n",
    "        \"De\": [],\n",
    "        \"Para\": [],\n",
    "    }\n",
    "    for from_to in from_to_cols:\n",
    "        from_stockpile, to_stockpile = from_to.split(\" -> \")\n",
    "        travel_times_dict[\"De\"].append(from_stockpile)\n",
    "        travel_times_dict[\"Para\"].append(to_stockpile)\n",
    "        for engine in all_engines:\n",
    "            vehicle_travel_times = travel_times_dict.get(f\"Veículo {engine}\", [])\n",
    "            engine_row = engines_df.loc[engines_df[\"id\"] == int(engine)]\n",
    "            time_travel = engine_row[from_to].values[0]\n",
    "            vehicle_travel_times.append(time_travel)\n",
    "            travel_times_dict[f\"Veículo {engine}\"] = vehicle_travel_times\n",
    "    \n",
    "    travel_times_df = pd.DataFrame(travel_times_dict).astype({\"De\": int, \"Para\": int})\n",
    "    \n",
    "    rename_dict = {\n",
    "        \"engine\": \"Veículo\",\n",
    "        \"stockpile\": \"Pilha\",\n",
    "        \"weightIni\": \"Peso Inicial Pilha\",\n",
    "        \"weightFinal\": \"Peso Final Pilha\",\n",
    "        \"weight\": \"Carregamento (ton)\",\n",
    "        \"start_time\": \"Início\",\n",
    "        \"end_time\": \"Fim\",\n",
    "        \"duration\": \"Tempo Carregamento\",\n",
    "        \"travel_time\": \"Tempo Deslocamento\",\n",
    "    }\n",
    "    operations_df = operations_df.rename(columns=rename_dict)[[*list(rename_dict.values()), *quality_cols]]\n",
    "    operations_df[quality_cols] = operations_df[quality_cols].round(2)\n",
    "    operations_df = operations_df.fillna(\"\")\n",
    "    \n",
    "    outputs_df_out[\"check\"] = np.where(\n",
    "        (outputs_df_out[\"value\"] >= outputs_df_out[\"minimum\"]) & \n",
    "        (outputs_df_out[\"value\"] <= outputs_df_out[\"maximum\"]),\n",
    "        True,\n",
    "        False,\n",
    "    )\n",
    "    rename_dict = {\n",
    "        \"parameter\": \"Elemento\",\n",
    "        \"value\": \"Valor\",\n",
    "        \"minimum\": \"Mínimo\",\n",
    "        \"maximum\": \"Máximo\",\n",
    "        \"goal\": \"Meta\",\n",
    "        \"check\": \"Check\",\n",
    "    }\n",
    "    outputs_df_out = outputs_df_out.rename(columns=rename_dict)[list(rename_dict.values())]\n",
    "    return operations_df, outputs_df_out\n",
    "\n",
    "\n",
    "def run_pyblend_command(input_json: str, output_json: str, algorithm: str = \"lahc\") -> None:\n",
    "    \"\"\"Runs the pyblend command with the specified input and output JSON files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_json : str\n",
    "        The input JSON file path.\n",
    "    output_json : str\n",
    "        The output JSON file path.\n",
    "    algorithm : str, optional\n",
    "        The algorithm to be used, by default \"lahc\".\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    RuntimeError\n",
    "        If the command fails to execute successfully.\n",
    "    \"\"\"\n",
    "    command = [\"python\", \"../pyblend\", input_json, output_json, \"-algorithm\", algorithm]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "        logging.info(\"Command executed successfully. Output:\\n%s\", result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logging.error(\"Command failed with error:\\n%s\", e.stderr)\n",
    "        raise RuntimeError(f\"Command failed: {e.stderr}\")\n",
    "\n",
    "\n",
    "class ExcelDataExtractor:\n",
    "    \"\"\"Class for extracting data from Excel sheets using xlwings.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    workbook_path : str\n",
    "        The path to the Excel workbook.\n",
    "    sheet_name : str\n",
    "        The name of the sheet from which data is extracted.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    extract_dataframe(range: str, expand: bool = True) -> pd.DataFrame:\n",
    "        Extracts a DataFrame from a specified range in the sheet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, workbook_path: str, sheet_name: str):\n",
    "        \"\"\"Initialize the ExcelDataExtractor with workbook path and sheet name.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        workbook_path : str\n",
    "            The path to the Excel workbook.\n",
    "        sheet_name : str\n",
    "            The name of the sheet from which data is extracted.\n",
    "        \"\"\"\n",
    "        self.wb = xw.Book(workbook_path)\n",
    "        self.sheet = self.wb.sheets[sheet_name]\n",
    "\n",
    "    def extract_dataframe(self, range: str, expand: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"Extracts a DataFrame from a specified range in the sheet.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        range : str\n",
    "            The cell range to start extracting data from.\n",
    "        expand : bool, optional\n",
    "            Whether to expand the range to a table, by default True.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Extracted data as a pandas DataFrame.\n",
    "        \"\"\"\n",
    "        return self.sheet[range].options(pd.DataFrame, expand='table' if expand else None).value.reset_index()\n",
    "\n",
    "\n",
    "class StockpileProcessor:\n",
    "    \"\"\"Class for processing stockpile data.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    process(stockpiles: pd.DataFrame, yards: pd.DataFrame, rename_dict: Dict[str, str]) -> pd.DataFrame:\n",
    "        Processes and merges stockpile and yard data.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def process(stockpiles: pd.DataFrame, yards: pd.DataFrame, rename_dict: Dict[str, str]) -> pd.DataFrame:\n",
    "        \"\"\"Processes and merges stockpile and yard data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stockpiles : pd.DataFrame\n",
    "            DataFrame containing stockpile information.\n",
    "        yards : pd.DataFrame\n",
    "            DataFrame containing yard information.\n",
    "        rename_dict : Dict[str, str]\n",
    "            Dictionary for renaming columns.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Merged DataFrame of stockpiles and yards.\n",
    "        \"\"\"\n",
    "        stockpiles = stockpiles.rename(columns=rename_dict).astype({col: int for col in rename_dict.values()})\n",
    "        yards = StockpileProcessor._process_yards(yards)\n",
    "        return stockpiles.merge(yards, on=\"yard\", how=\"left\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _process_yards(yards: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Processes the yard data to extract rails information.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        yards : pd.DataFrame\n",
    "            DataFrame containing yard information.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Processed DataFrame with rails information.\n",
    "        \"\"\"\n",
    "        engine_cols = [col for col in yards.columns if any(ch.isnumeric() for ch in col)]\n",
    "        rename_dict = {col: \"\".join(ch for ch in col if ch.isnumeric()) for col in engine_cols}\n",
    "        engine_ids = list(rename_dict.values())\n",
    "\n",
    "        yards = yards.rename(columns=rename_dict).astype({\"yard\": int})\n",
    "        yards[\"rails\"] = yards[engine_ids].apply(\n",
    "            lambda row: [idx for idx, value in enumerate(row, 1) if pd.notna(value)], axis=1)\n",
    "        return yards.drop(columns=engine_ids)\n",
    "\n",
    "\n",
    "class TravelSpeedProcessor:\n",
    "    \"\"\"Class for processing travel speed data.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    process(travel_speed: pd.DataFrame, rename_dict: Dict[str, str]) -> List[List[float]]:\n",
    "        Processes travel speed data into a list of travel times.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def process(travel_speed: pd.DataFrame, rename_dict: Dict[str, str]) -> List[List[float]]:\n",
    "        \"\"\"Processes travel speed data into a list of travel times.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        travel_speed : pd.DataFrame\n",
    "            DataFrame containing travel speed data.\n",
    "        rename_dict : Dict[str, str]\n",
    "            Dictionary for renaming columns.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List[List[float]]\n",
    "            Nested list representing travel times between locations.\n",
    "        \"\"\"\n",
    "        travel_speed = travel_speed.rename(columns=rename_dict)\n",
    "        stockpiles_from_to_cols = list(rename_dict.values())\n",
    "        speed_cols = travel_speed.columns.difference(stockpiles_from_to_cols)\n",
    "\n",
    "        travel_speed[\"travel_time\"] = travel_speed[speed_cols[0]]\n",
    "        for col in speed_cols[1:]:\n",
    "            travel_speed[\"travel_time\"] = travel_speed[\"travel_time\"].fillna(travel_speed[col])\n",
    "\n",
    "        return travel_speed.drop(columns=speed_cols).pivot_table(\n",
    "            index=[\"from\"], columns=[\"to\"], values=[\"travel_time\"]).values.tolist()\n",
    "\n",
    "\n",
    "class InstanceDataBuilder:\n",
    "    \"\"\"Class for building the instance data JSON structure.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    build_instance_data\n",
    "        Builds the instance data structure.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def build_instance_data(\n",
    "        stockpiles: pd.DataFrame,\n",
    "        engines: pd.DataFrame,\n",
    "        travel_times: List[List[float]],\n",
    "        inputs: List[Dict[str, Any]],\n",
    "        outputs: List[Dict[str, Any]],\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Builds the instance data structure.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stockpiles : pd.DataFrame\n",
    "            DataFrame containing stockpile information.\n",
    "        engines : pd.DataFrame\n",
    "            DataFrame containing engine information.\n",
    "        travel_times : List[List[float]]\n",
    "            Nested list representing travel times between locations.\n",
    "        inputs : List[Dict[str, Any]]\n",
    "            List of dictionaries representing input data.\n",
    "        outputs : List[Dict[str, Any]]\n",
    "            List of dictionaries representing output data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            The constructed instance data structure.\n",
    "        \"\"\"\n",
    "        instance_data = {\n",
    "            \"info\": [\"Instance_Interactive\", 1000, 1],\n",
    "            \"stockpiles\": [],\n",
    "            \"engines\": [],\n",
    "            \"inputs\": inputs,\n",
    "            \"outputs\": outputs,\n",
    "            \"distancesTravel\": travel_times,\n",
    "            \"timeTravel\": travel_times\n",
    "        }\n",
    "\n",
    "        for _, row in stockpiles.iterrows():\n",
    "            sp = {\n",
    "                \"id\": int(row[\"id\"]),\n",
    "                \"position\": int(row[\"id\"]) - 1,\n",
    "                \"yard\": int(row[\"yard\"]),\n",
    "                \"rails\": [int(r) for r in row[\"rails\"]],\n",
    "                \"capacity\": int(row[\"weightIni\"]),\n",
    "                \"weightIni\": int(row[\"weightIni\"]),\n",
    "                \"qualityIni\": [\n",
    "                    {\"parameter\": \"Fe\", \"value\": float(row[\"Fe\"])},\n",
    "                    {\"parameter\": \"SiO2\", \"value\": float(row[\"SiO2\"])},\n",
    "                    {\"parameter\": \"Al2O3\", \"value\": float(row[\"Al2O3\"])},\n",
    "                    {\"parameter\": \"P\", \"value\": float(row[\"P\"])}\n",
    "                ]\n",
    "            }\n",
    "            instance_data[\"stockpiles\"].append(sp)\n",
    "\n",
    "        all_yards = [int(y) for y in stockpiles[\"yard\"].drop_duplicates().to_list()]\n",
    "        for _, row in engines.iterrows():\n",
    "            eng = {\n",
    "                \"id\": int(row[\"id\"]),\n",
    "                \"speedStack\": 0.0,\n",
    "                \"speedReclaim\": int(row[\"speedReclaim\"]),\n",
    "                \"posIni\": int(row[\"id\"]),\n",
    "                \"rail\": int(row[\"id\"]),\n",
    "                \"yards\": all_yards\n",
    "            }\n",
    "            instance_data[\"engines\"].append(eng)\n",
    "\n",
    "        return instance_data\n",
    "\n",
    "\n",
    "def update_excel_sheets(operations_df: pd.DataFrame, outputs_df_out: pd.DataFrame, excel_file: str) -> None:\n",
    "    \"\"\"Update the Excel sheets with the new data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    operations_df : pd.DataFrame\n",
    "        DataFrame containing operation results.\n",
    "    outputs_df_out : pd.DataFrame\n",
    "        DataFrame containing output check results.\n",
    "    excel_file : str\n",
    "        Path to the Excel file to be updated.\n",
    "    \"\"\"\n",
    "    wb = xw.Book(excel_file)\n",
    "    resultados_sheet = wb.sheets['Resultados']\n",
    "    check_res_sheet = wb.sheets['Check Restrições']\n",
    "\n",
    "    # Clear existing data\n",
    "    resultados_sheet.clear_contents()\n",
    "    check_res_sheet.clear_contents()\n",
    "\n",
    "    # Write new data\n",
    "    operations_df = operations_df.fillna('')\n",
    "    operations_df.iloc[-1, 0] = operations_df.iloc[0, -1].astype(str)\n",
    "    operations_df = operations_df.set_index(operations_df.columns[0])\n",
    "    \n",
    "    resultados_sheet.range(\"A1\").value = operations_df\n",
    "    check_res_sheet.range(\"A1\").value = outputs_df_out.fillna('').set_index(outputs_df_out.columns[0])\n",
    "\n",
    "\n",
    "def main(\n",
    "    excel_filepath: str,\n",
    "    instance_json_path: str,\n",
    "    output_json_path: str,\n",
    "):\n",
    "    # Initialize the ExcelDataExtractor with workbook path and sheet name\n",
    "    extractor = ExcelDataExtractor(excel_filepath, \"Inputs\")\n",
    "\n",
    "    # Extract data from the Excel sheet\n",
    "    stockpiles_df = extractor.extract_dataframe('D2')\n",
    "    yards_df = extractor.extract_dataframe('L2')\n",
    "    engines_df = extractor.extract_dataframe('P2').rename(columns={\"Veículo\": \"id\", \"Taxa (ton/min)\": \"speedReclaim\"}).astype(int)\n",
    "    travel_speed_df = extractor.extract_dataframe('S2')\n",
    "\n",
    "    # Process stockpile and yard data\n",
    "    stockpiles = StockpileProcessor.process(stockpiles_df, yards_df, {\"ID\": \"id\", \"Área\": \"yard\", \"Quantidade (ton)\": \"weightIni\"})\n",
    "\n",
    "    # Process travel speed data\n",
    "    travel_times = TravelSpeedProcessor.process(travel_speed_df, {\"De\": \"from\", \"Para\": \"to\"})\n",
    "\n",
    "    output_info = extractor.extract_dataframe(\"A2\")\n",
    "    outputs = [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"destination\": 1,\n",
    "            \"weight\": int(output_info.iloc[0, 1]),\n",
    "            \"quality\": [\n",
    "                {\"parameter\": \"Fe\", \"minimum\": 60, \"maximum\": 100, \"goal\": 65, \"importance\": 10},\n",
    "                {\"parameter\": \"SiO2\", \"minimum\": 2.8, \"maximum\": 5.8, \"goal\": 5.8, \"importance\": 1000},\n",
    "                {\"parameter\": \"Al2O3\", \"minimum\": 2.5, \"maximum\": 4.9, \"goal\": 4.9, \"importance\": 100},\n",
    "                {\"parameter\": \"P\", \"minimum\": 0.05, \"maximum\": 0.07, \"goal\": 0.07, \"importance\": 100},\n",
    "            ],\n",
    "            \"time\": 600\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    inputs = [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"weight\": 0.0,\n",
    "            \"quality\": [\n",
    "                {\"parameter\": \"Fe\", \"value\": 60},\n",
    "                {\"parameter\": \"SiO2\", \"value\": 1.5},\n",
    "                {\"parameter\": \"Al2O3\", \"value\": 0.8},\n",
    "                {\"parameter\": \"P\", \"value\": 1.0}\n",
    "            ],\n",
    "            \"time\": 8.0\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Build the instance data structure\n",
    "    instance_data = InstanceDataBuilder.build_instance_data(stockpiles, engines_df, travel_times, inputs, outputs)\n",
    "\n",
    "    # Write the data to a JSON file\n",
    "    with open(instance_json_path, \"w\") as json_file:\n",
    "        json.dump(instance_data, json_file, indent=2)\n",
    "\n",
    "    run_pyblend_command(Path(instance_json_path).name, output_json_path)\n",
    "\n",
    "    operations_df, outputs_df_out = json_input_output_to_excel(\n",
    "        instance_data,\n",
    "        output_json_path,\n",
    "    )\n",
    "    update_excel_sheets(operations_df, outputs_df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53020828-3574-4591-8803-955000259f69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T08:57:10.192840Z",
     "iopub.status.busy": "2024-08-30T08:57:10.192313Z",
     "iopub.status.idle": "2024-08-30T08:57:11.786038Z",
     "shell.execute_reply": "2024-08-30T08:57:11.784633Z",
     "shell.execute_reply.started": "2024-08-30T08:57:10.192784Z"
    }
   },
   "outputs": [],
   "source": [
    "main(\n",
    "    \"/Users/erikingwersen/Desktop/fileshare/out/excel/out_interactive.xlsm\",\n",
    "    \"../tests/instance_interactive.json\",\n",
    "    \"../out/json/out_interactive.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18548a46-8757-458f-bb7c-c6b762796b14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T09:16:10.728474Z",
     "iopub.status.busy": "2024-08-30T09:16:10.728126Z",
     "iopub.status.idle": "2024-08-30T09:16:15.916908Z",
     "shell.execute_reply": "2024-08-30T09:16:15.916053Z",
     "shell.execute_reply.started": "2024-08-30T09:16:10.728444Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:296: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  engines_df[from_to_df[\"from_to\"].to_list()] = -1\n",
      "/var/folders/t5/5_nvwwz94jq9nfwy6zv8s3_40000gn/T/ipykernel_17442/1283604484.py:340: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  xdf.groupby(\"engine\", as_index=False).apply(travel_time)\n"
     ]
    }
   ],
   "source": [
    "operations_df, outputs_df_out = json_input_output_to_excel(\n",
    "    \"../tests/instance_interactive.json\",\n",
    "    \"../out/json/out_interactive.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4542dedb-d947-4122-87eb-7bf89c85475a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T09:16:15.919102Z",
     "iopub.status.busy": "2024-08-30T09:16:15.918692Z",
     "iopub.status.idle": "2024-08-30T09:16:15.940025Z",
     "shell.execute_reply": "2024-08-30T09:16:15.938721Z",
     "shell.execute_reply.started": "2024-08-30T09:16:15.919074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Veículo</th>\n",
       "      <th>Pilha</th>\n",
       "      <th>Peso Inicial Pilha</th>\n",
       "      <th>Peso Final Pilha</th>\n",
       "      <th>Carregamento (ton)</th>\n",
       "      <th>Início</th>\n",
       "      <th>Fim</th>\n",
       "      <th>Tempo Carregamento</th>\n",
       "      <th>Tempo Deslocamento</th>\n",
       "      <th>Fe</th>\n",
       "      <th>SiO2</th>\n",
       "      <th>Al2O3</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>45000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>12.44</td>\n",
       "      <td>11.54</td>\n",
       "      <td>0.90</td>\n",
       "      <td>65.20</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>45000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45000</td>\n",
       "      <td>13.94</td>\n",
       "      <td>25.48</td>\n",
       "      <td>11.54</td>\n",
       "      <td>1.50</td>\n",
       "      <td>60.30</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>62500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62500</td>\n",
       "      <td>25.64</td>\n",
       "      <td>41.67</td>\n",
       "      <td>16.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>68.10</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>70000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70000</td>\n",
       "      <td>42.88</td>\n",
       "      <td>60.83</td>\n",
       "      <td>17.95</td>\n",
       "      <td>1.21</td>\n",
       "      <td>65.90</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>75000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75000</td>\n",
       "      <td>61.93</td>\n",
       "      <td>81.16</td>\n",
       "      <td>19.23</td>\n",
       "      <td>1.10</td>\n",
       "      <td>65.40</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>67500</td>\n",
       "      <td>66250.0</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.70</td>\n",
       "      <td>69.40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000</td>\n",
       "      <td>1.34</td>\n",
       "      <td>20.57</td>\n",
       "      <td>19.23</td>\n",
       "      <td>0.16</td>\n",
       "      <td>68.30</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60000</td>\n",
       "      <td>58750.0</td>\n",
       "      <td>1250</td>\n",
       "      <td>21.27</td>\n",
       "      <td>21.75</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.70</td>\n",
       "      <td>10.30</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>45000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45000</td>\n",
       "      <td>22.65</td>\n",
       "      <td>39.96</td>\n",
       "      <td>17.31</td>\n",
       "      <td>0.90</td>\n",
       "      <td>76.30</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>65000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65000</td>\n",
       "      <td>40.76</td>\n",
       "      <td>65.76</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>67.00</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40000</td>\n",
       "      <td>65.82</td>\n",
       "      <td>81.20</td>\n",
       "      <td>15.38</td>\n",
       "      <td>0.06</td>\n",
       "      <td>75.00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>output</td>\n",
       "      <td>125000</td>\n",
       "      <td></td>\n",
       "      <td>500000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>81.20</td>\n",
       "      <td>81.20</td>\n",
       "      <td>8.19</td>\n",
       "      <td>67.45</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Veículo   Pilha  Peso Inicial Pilha Peso Final Pilha  Carregamento (ton)  \\\n",
       "0        1      11               45000              0.0               45000   \n",
       "1        1       8               45000              0.0               45000   \n",
       "2        1      17               62500              0.0               62500   \n",
       "3        1      20               70000              0.0               70000   \n",
       "4        1       6               75000              0.0               75000   \n",
       "5        2      19               67500          66250.0                1250   \n",
       "6        2       9               50000              0.0               50000   \n",
       "7        2       1               60000          58750.0                1250   \n",
       "8        2       2               45000              0.0               45000   \n",
       "9        2      18               65000              0.0               65000   \n",
       "10       2       7               40000              0.0               40000   \n",
       "0   [1, 2]  output              125000                               500000   \n",
       "\n",
       "    Início    Fim  Tempo Carregamento  Tempo Deslocamento     Fe  SiO2  Al2O3  \\\n",
       "0     0.90  12.44               11.54                0.90  65.20   4.1    4.9   \n",
       "1    13.94  25.48               11.54                1.50  60.30   5.5    4.7   \n",
       "2    25.64  41.67               16.03                0.16  68.10   3.6    4.8   \n",
       "3    42.88  60.83               17.95                1.21  65.90   4.4    5.2   \n",
       "4    61.93  81.16               19.23                1.10  65.40   4.5    4.9   \n",
       "5     0.70   1.18                0.48                0.70  69.40   4.0    5.1   \n",
       "6     1.34  20.57               19.23                0.16  68.30   3.2    4.8   \n",
       "7    21.27  21.75                0.48                0.70  10.30   2.3    4.5   \n",
       "8    22.65  39.96               17.31                0.90  76.30   5.6    4.8   \n",
       "9    40.76  65.76               25.00                0.80  67.00   3.9    4.9   \n",
       "10   65.82  81.20               15.38                0.06  75.00   4.3    5.0   \n",
       "0     0.70  81.20               81.20                8.19  67.45   4.3    4.9   \n",
       "\n",
       "       P  \n",
       "0   0.05  \n",
       "1   0.06  \n",
       "2   0.06  \n",
       "3   0.09  \n",
       "4   0.06  \n",
       "5   0.08  \n",
       "6   0.07  \n",
       "7   0.05  \n",
       "8   0.05  \n",
       "9   0.07  \n",
       "10  0.08  \n",
       "0   0.07  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbe75d2f-e70a-41ab-836f-21442b8ca12b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T09:15:50.384353Z",
     "iopub.status.busy": "2024-08-30T09:15:50.383975Z",
     "iopub.status.idle": "2024-08-30T09:15:50.611994Z",
     "shell.execute_reply": "2024-08-30T09:15:50.610712Z",
     "shell.execute_reply.started": "2024-08-30T09:15:50.384325Z"
    }
   },
   "outputs": [],
   "source": [
    "excel_file = \"/Users/erikingwersen/Desktop/fileshare/out/excel/out_interactive.xlsm\"\n",
    "wb = xw.Book(excel_file)\n",
    "\n",
    "resultados_sheet = wb.sheets['Resultados']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "921023b1-b1e7-4a65-8a88-a40b7742f76d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T09:18:41.344005Z",
     "iopub.status.busy": "2024-08-30T09:18:41.343676Z",
     "iopub.status.idle": "2024-08-30T09:18:41.348799Z",
     "shell.execute_reply": "2024-08-30T09:18:41.347916Z",
     "shell.execute_reply.started": "2024-08-30T09:18:41.343977Z"
    }
   },
   "outputs": [],
   "source": [
    "operations_df = operations_df.fillna('')\n",
    "operations_df.iloc[-1, 0] = operations_df.iloc[0, -1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e471c816-3ddc-4300-9b38-de9e4123f8b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T09:18:41.964515Z",
     "iopub.status.busy": "2024-08-30T09:18:41.964168Z",
     "iopub.status.idle": "2024-08-30T09:18:42.130670Z",
     "shell.execute_reply": "2024-08-30T09:18:42.129927Z",
     "shell.execute_reply.started": "2024-08-30T09:18:41.964489Z"
    }
   },
   "outputs": [],
   "source": [
    "resultados_sheet['A1'].value = operations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "966591ac-035a-4e58-a3e3-cb9103437eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T09:20:20.297958Z",
     "iopub.status.busy": "2024-08-30T09:20:20.297477Z",
     "iopub.status.idle": "2024-08-30T09:20:20.596732Z",
     "shell.execute_reply": "2024-08-30T09:20:20.595802Z",
     "shell.execute_reply.started": "2024-08-30T09:20:20.297916Z"
    }
   },
   "outputs": [],
   "source": [
    "update_excel_sheets(operations_df, outputs_df_out, \"/Users/erikingwersen/Desktop/fileshare/out/excel/out_interactive.xlsm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f5de6f8-1737-4f4d-afbe-a077e08994d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T09:02:26.096174Z",
     "iopub.status.busy": "2024-08-30T09:02:26.095684Z",
     "iopub.status.idle": "2024-08-30T09:02:26.111470Z",
     "shell.execute_reply": "2024-08-30T09:02:26.110377Z",
     "shell.execute_reply.started": "2024-08-30T09:02:26.096114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elemento</th>\n",
       "      <th>Valor</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>Máximo</th>\n",
       "      <th>Meta</th>\n",
       "      <th>Check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fe</td>\n",
       "      <td>67.45</td>\n",
       "      <td>60.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SiO2</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.80</td>\n",
       "      <td>5.80</td>\n",
       "      <td>5.80</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al2O3</td>\n",
       "      <td>4.90</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Elemento  Valor  Mínimo  Máximo   Meta  Check\n",
       "0       Fe  67.45   60.00  100.00  65.00   True\n",
       "1     SiO2   4.30    2.80    5.80   5.80   True\n",
       "2    Al2O3   4.90    2.50    4.90   4.90   True\n",
       "3        P   0.07    0.05    0.07   0.07   True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdc2d2e-e830-4332-8d31-a6de9e123a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
